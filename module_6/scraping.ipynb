{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "import gzip\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from tempfile import TemporaryDirectory \n",
    "from pathlib import Path, PurePath\n",
    "from tqdm.notebook import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scrapy in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: Twisted[http2]>=17.9.0 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from scrapy) (21.7.0)\n",
      "Requirement already satisfied: service-identity>=16.0.0 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from scrapy) (21.1.0)\n",
      "Requirement already satisfied: zope.interface>=4.1.3 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from scrapy) (5.1.2)\n",
      "Requirement already satisfied: h2<4.0,>=3.0 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from scrapy) (3.2.0)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5; platform_python_implementation == \"CPython\" in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from scrapy) (2.0.5)\n",
      "Requirement already satisfied: protego>=0.1.15 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from scrapy) (0.1.16)\n",
      "Requirement already satisfied: cssselect>=0.9.1 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from scrapy) (1.1.0)\n",
      "Requirement already satisfied: parsel>=1.5.0 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from scrapy) (1.6.0)\n",
      "Requirement already satisfied: lxml>=3.5.0; platform_python_implementation == \"CPython\" in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from scrapy) (4.6.1)\n",
      "Requirement already satisfied: itemadapter>=0.1.0 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from scrapy) (0.3.0)\n",
      "Requirement already satisfied: cryptography>=2.0 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from scrapy) (3.1.1)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from scrapy) (1.22.0)\n",
      "Requirement already satisfied: pyOpenSSL>=16.2.0 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from scrapy) (19.1.0)\n",
      "Requirement already satisfied: itemloaders>=1.0.1 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from scrapy) (1.0.4)\n",
      "Requirement already satisfied: queuelib>=1.4.2 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from scrapy) (1.6.1)\n",
      "Requirement already satisfied: twisted-iocpsupport~=1.0.0; platform_system == \"Windows\" in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from Twisted[http2]>=17.9.0->scrapy) (1.0.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from Twisted[http2]>=17.9.0->scrapy) (20.3.0)\n",
      "Requirement already satisfied: Automat>=0.8.0 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from Twisted[http2]>=17.9.0->scrapy) (20.2.0)\n",
      "Requirement already satisfied: incremental>=21.3.0 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from Twisted[http2]>=17.9.0->scrapy) (21.3.0)\n",
      "Requirement already satisfied: constantly>=15.1 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from Twisted[http2]>=17.9.0->scrapy) (15.1.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from Twisted[http2]>=17.9.0->scrapy) (21.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from Twisted[http2]>=17.9.0->scrapy) (3.7.4.3)\n",
      "Requirement already satisfied: priority<2.0,>=1.1.0; extra == \"http2\" in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from Twisted[http2]>=17.9.0->scrapy) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy) (0.2.8)\n",
      "Requirement already satisfied: six in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy) (1.15.0)\n",
      "Requirement already satisfied: pyasn1 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from service-identity>=16.0.0->scrapy) (0.4.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from zope.interface>=4.1.3->scrapy) (50.3.1.post20201107)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from h2<4.0,>=3.0->scrapy) (3.0.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from h2<4.0,>=3.0->scrapy) (5.2.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from cryptography>=2.0->scrapy) (1.14.3)\n",
      "Requirement already satisfied: jmespath>=0.9.5 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from itemloaders>=1.0.1->scrapy) (0.10.0)\n",
      "Requirement already satisfied: idna>=2.5 in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from hyperlink>=17.1.1->Twisted[http2]>=17.9.0->scrapy) (2.10)\n",
      "Requirement already satisfied: pycparser in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.0->scrapy) (2.20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: itemadapter in c:\\users\\allkotraz\\anaconda3\\lib\\site-packages (0.3.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pip.main(['install', 'scrapy'])\n",
    "pip.main(['install', 'itemadapter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Path('.').resolve().parents[0].joinpath('module_6/input', 'links.csv')\n",
    "sitemap_link='https://auto.ru/sitemapindex.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 125 link lists as gzipped xml files.\n"
     ]
    }
   ],
   "source": [
    "temp_fold = TemporaryDirectory()\n",
    "temp_path = Path(temp_fold.name)\n",
    "r = requests.get(sitemap_link)\n",
    "text = r.content.decode()\n",
    "soup = BeautifulSoup(text, 'lxml')\n",
    "links_to_gz = []\n",
    "i = 0\n",
    "for element in soup.find_all('loc'):\n",
    "    links_to_gz.append(element.text.strip())\n",
    "    i += 1\n",
    "print(f'Found {i} link lists as gzipped xml files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "offers_cars = [x for x in links_to_gz if 'offers_cars' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104c63c3dab94a5a9772b7a2369ea72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloaded 11 link files\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for link in tqdm(offers_cars):\n",
    "    tempfile = temp_path / link.split('/')[-1]\n",
    "    if not tempfile.is_file():\n",
    "        r = requests.get(link, allow_redirects=True)\n",
    "        with tempfile.open('wb') as file:\n",
    "            file.write(r.content)\n",
    "        i+=1\n",
    "print(f'Downloaded {i} link files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ae84cd505c4f4eb6c6572a42651d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unzipped 11 txt files.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for gz in tqdm(list(temp_path.iterdir())):\n",
    "    gz = gz.resolve()\n",
    "    if gz.suffix == '.gz':\n",
    "        with gzip.open(gz) as archive:\n",
    "            with open(gz.parent / gz.stem, 'wb') as output_file:\n",
    "                output_file.write(archive.read())\n",
    "        gz.unlink()\n",
    "    i += 1\n",
    "print(f'Unzipped {i} txt files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e2c66473a14edbb97432ae21ba938b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300004 links in file C:\\Users\\ALLKOT~1\\AppData\\Local\\Temp\\tmph26a88hb\\sitemap_offers_cars_1.xml, totally 300004 links\n",
      "Found 300004 links in file C:\\Users\\ALLKOT~1\\AppData\\Local\\Temp\\tmph26a88hb\\sitemap_offers_cars_10.xml, totally 600008 links\n",
      "Found 252340 links in file C:\\Users\\ALLKOT~1\\AppData\\Local\\Temp\\tmph26a88hb\\sitemap_offers_cars_11.xml, totally 852348 links\n",
      "Found 300004 links in file C:\\Users\\ALLKOT~1\\AppData\\Local\\Temp\\tmph26a88hb\\sitemap_offers_cars_2.xml, totally 1152352 links\n",
      "Found 300004 links in file C:\\Users\\ALLKOT~1\\AppData\\Local\\Temp\\tmph26a88hb\\sitemap_offers_cars_3.xml, totally 1452356 links\n",
      "Found 300004 links in file C:\\Users\\ALLKOT~1\\AppData\\Local\\Temp\\tmph26a88hb\\sitemap_offers_cars_4.xml, totally 1752360 links\n",
      "Found 300004 links in file C:\\Users\\ALLKOT~1\\AppData\\Local\\Temp\\tmph26a88hb\\sitemap_offers_cars_5.xml, totally 2052364 links\n",
      "Found 300004 links in file C:\\Users\\ALLKOT~1\\AppData\\Local\\Temp\\tmph26a88hb\\sitemap_offers_cars_6.xml, totally 2352368 links\n",
      "Found 300004 links in file C:\\Users\\ALLKOT~1\\AppData\\Local\\Temp\\tmph26a88hb\\sitemap_offers_cars_7.xml, totally 2652372 links\n",
      "Found 300004 links in file C:\\Users\\ALLKOT~1\\AppData\\Local\\Temp\\tmph26a88hb\\sitemap_offers_cars_8.xml, totally 2952376 links\n",
      "Found 300004 links in file C:\\Users\\ALLKOT~1\\AppData\\Local\\Temp\\tmph26a88hb\\sitemap_offers_cars_9.xml, totally 3252380 links\n",
      "\n",
      "Output written to file C:\\Users\\allkotraz\\PY\\Py\\Local-SkillFactory\\module_6\\input\\links.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "offers_list = []\n",
    "for txt in tqdm(list(temp_path.iterdir())):\n",
    "    offers_counter = 0\n",
    "    with open(txt, 'r') as f:\n",
    "        file_content = f.read().splitlines()\n",
    "        offers_list += file_content\n",
    "        print(f'Found {len(file_content)} links in file {txt}, totally {len(offers_list)} links')\n",
    "# write this list to csv\n",
    "output_path = Path(output).resolve()\n",
    "with output_path.open('w+', newline='') as f:\n",
    "    wr = csv.writer(f)\n",
    "    for line in offers_list:\n",
    "        wr.writerow([line])\n",
    "print(f'Output written to file {str(output_path)}')\n",
    "# cleanup temp folder\n",
    "temp_fold.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bashCommand = \"\"\"%%bash\n",
    "cd .. &&\n",
    "touch './input/dataset_with_electro.csv' &&\n",
    "output_file_path=$(realpath ./input/dataset_with_electro.csv) &&\n",
    "links_file=$(realpath ./input/links.csv) && \n",
    "cd ./auto_ru_scrapy && \n",
    "scrapy crawl -a links_file=$links_file -o $output_file_path -L ERROR auto_ru_scraper\"\"\"\n",
    "import subprocess\n",
    "process = subprocess.Popen(bashCommand, stdout=subprocess.PIPE, shell=True)\n",
    "output, error = process.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = Path('.').resolve().parents[0].joinpath('module_6/input')\n",
    "test_links = pd.read_csv(input_path.joinpath('test.csv'), usecols=['car_url'])\n",
    "test_links.to_csv(input_path.joinpath('test_links.csv'), header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd .. &&\n",
    "touch './input/test_scraped.csv' &&\n",
    "output_file_path=$(realpath ./input/test_scraped.csv) &&\n",
    "links_file=$(realpath ./input/test_links.csv) && \n",
    "cd ./auto_ru_scrapy && \n",
    "scrapy crawl -a links_file=$links_file -o $output_file_path -L ERROR auto_ru_scraper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
